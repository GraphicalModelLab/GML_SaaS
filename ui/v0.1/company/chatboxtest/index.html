<!DOCTYPE html>
<html>
<head>

    <script src="./chatBoxAlgorithms/recurrent.js"></script>

    <script type="text/javascript">
        alert("init");
        var sample_softmax_temperature = 1.0; // how peaky model predictions should be
        var max_chars_gen = 100; // max length of generated sentences


        var regc = 0.000001; // L2 regularization strength
        var learning_rate = 0.01; // learning rate
        var clipval = 5.0; // clip gradients at this value
        var generator = "lstm";
        var hidden_sizes = [10,10];
        var epoch_size = 10;
        var input_size = 27;
        var output_size = 10;
        var letter_size = 5; // size of letter embeddings
        var letterToIndex = {};
        var indexToLetter = {};
        var vocab = [];
        var data_sents = [];
        var solver = new R.Solver(); // should be class because it needs memory for step caches

        var model = {};

        var initVocab = function(sents, count_threshold) {
          // go over all characters and keep track of all unique ones seen
          var txt = sents.join(''); // concat all

          // count up all characters
          var d = {};
          for(var i=0,n=txt.length;i<n;i++) {
            var txti = txt[i];
            if(txti in d) { d[txti] += 1; }
            else { d[txti] = 1; }
          }

          // filter by count threshold and create pointers
          letterToIndex = {};
          indexToLetter = {};
          vocab = [];
          // NOTE: start at one because we will have START and END tokens!
          // that is, START token will be index 0 in model letter vectors
          // and END token will be index 0 in the next character softmax
          var q = 1;
          for(ch in d) {
            if(d.hasOwnProperty(ch)) {
              if(d[ch] >= count_threshold) {
                // add character to vocab
                letterToIndex[ch] = q;
                indexToLetter[q] = ch;
                vocab.push(ch);
                q++;
              }
            }
          }
        }

        var forwardIndex = function(G, model, ix, prev) {
          // 10 is in
          var x = G.rowPluck(model['Wil'], ix);
          // forward prop the sequence learner
          if(generator === 'rnn') {
            var out_struct = R.forwardRNN(G, model, hidden_sizes, x, prev);
          } else {
            var out_struct = R.forwardLSTM(G, model, hidden_sizes, x, prev);
          }
          return out_struct;
        }

        var predictSentence = function(model, samplei, temperature) {
          if(typeof samplei === 'undefined') { samplei = false; }
          if(typeof temperature === 'undefined') { temperature = 1.0; }

          var G = new R.Graph(false);
          var s = '';
          var prev = {};
          while(true) {

            // RNN tick
            var ix = s.length === 0 ? 0 : letterToIndex[s[s.length-1]];
            var lh = forwardIndex(G, model, ix, prev);
            prev = lh;

            // sample predicted letter
            logprobs = lh.o;
            if(temperature !== 1.0 && samplei) {
              // scale log probabilities by temperature and renormalize
              // if temperature is high, logprobs will go towards zero
              // and the softmax outputs will be more diffuse. if temperature is
              // very low, the softmax outputs will be more peaky
              for(var q=0,nq=logprobs.w.length;q<nq;q++) {
                logprobs.w[q] /= temperature;
              }
            }

            probs = R.softmax(logprobs);
            if(samplei) {
              var ix = R.samplei(probs.w);
            } else {
              var ix = R.maxi(probs.w);
            }

            if(ix === 0) break; // END token predicted, break out
            if(s.length > max_chars_gen) { break; } // something is wrong

            var letter = indexToLetter[ix];
            s += letter;
          }
          return s;
        }

        var costfun = function(model, sent) {
          // takes a model and a sentence and
          // calculates the loss. Also returns the Graph
          // object which can be used to do backprop
          var n = sent.length;
          var G = new R.Graph();
          var log2ppl = 0.0;
          var cost = 0.0;
          var prev = {};

          console.log("costfun : -1 ~ "+n);
          for(var i=-1;i<n;i++) {
            // start and end tokens are zeros
            var ix_source = i === -1 ? 0 : letterToIndex[sent[i]]; // first step: start with START token
            var ix_target = i === n-1 ? 0 : letterToIndex[sent[i+1]]; // last step: end with END token

            console.log("costfunc:"+n+","+i+"::"+ix_source+","+ix_target);
            lh = forwardIndex(G, model, ix_source, prev);
            prev = lh;

            // set gradients into logprobabilities
            logprobs = lh.o; // interpret output as logprobs
            probs = R.softmax(logprobs); // compute the softmax probabilities

            log2ppl += -Math.log2(probs.w[ix_target]); // accumulate base 2 log prob and do smoothing
            cost += -Math.log(probs.w[ix_target]);

            // write gradients into log probabilities
            logprobs.dw = probs.w;
            logprobs.dw[ix_target] -= 1
          }
          var ppl = Math.pow(2, log2ppl / (n - 1));
          return {'G':G, 'ppl':ppl, 'cost':cost};
        }


        var tick = function() {

          // sample sentence fromd data
          var sentix = R.randi(0,data_sents.length);
          var sent = data_sents[sentix];

          var t0 = +new Date();  // log start timestamp

          // evaluate cost function on a sentence
          console.log("data to train");
          console.log(sent);
          var cost_struct = costfun(model, sent);

          // use built up graph to compute backprop (set .dw fields in mats)
          cost_struct.G.backward();
          // perform param update
          var solver_stats = solver.step(model, learning_rate, regc, clipval);

          var t1 = +new Date();
          var tick_time = t1 - t0;


          var pred = predictSentence(model, true, sample_softmax_temperature);

          alert("what is pred ? "+pred);
        }

        var utilAddToModel = function(modelto, modelfrom) {
          for(var k in modelfrom) {
            if(modelfrom.hasOwnProperty(k)) {
              // copy over the pointer but change the key to use the append
              modelto[k] = modelfrom[k];
            }
          }
        }

        var initModel = function() {
          // letter embedding vectors
          var model = {};
          model['Wil'] = new R.RandMat(input_size, letter_size , 0, 0.08);

          if(generator === 'rnn') {
            var rnn = R.initRNN(letter_size, hidden_sizes, output_size);
            utilAddToModel(model, rnn);
          } else {
            var lstm = R.initLSTM(letter_size, hidden_sizes, output_size);
            utilAddToModel(model, lstm);
          }

          return model;
        }

        var data_sents = [];
        data_sents.push("abcdefghijklmnopqrstuvwxyz");
        initVocab(data_sents, 1);
        model = initModel();

        alert("Hello");
        console.log(model["Wil"]);
        tick();
    </script>
</head>

<body>

</body>
</html>